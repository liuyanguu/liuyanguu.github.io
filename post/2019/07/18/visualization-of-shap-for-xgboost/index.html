<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>SHAP for XGBoost in R: SHAPforxgboost | Welcome to my blog</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">

  </head>

  <body class="page">
    <nav class="header">
      <div class="banner">
<a href="/">

<img src="/ocean%202.jpg" alt="Text on Image" />
</a>
</div>

      <div class="head-meta">
      
        <span><a href="/">&larr; Back to Home</a></span>
        <span class="date">2019-07-18</span>
        
        
        
          
        
        
        
        <span><a href="https://github.com/liuyanguu/Blogdown/edit/master/hugo-xmag/content/post/2019-07-18-visualization-of-shap-for-xgboost.Rmd">Edit this page &rarr;</a></span>
        
        
      
      </div>
    </nav>

<div class="container">
<article>
<div class="article-meta">

  <div class="categories">
  
    <a href="/categories/r-package">R package</a>
  
     &hercon; <a href="/categories/machine-learning">Machine Learning</a>
  
     &hercon; <a href="/categories/data-visualization">Data Visualization</a>
  
  </div>

  <h1><span class="title">SHAP for XGBoost in R: SHAPforxgboost</span></h1>

  
  <h3 class="author">Yang Liu
</h3>
  

  
  <p>Tags: <a href="/tags/xgboost">XGBoost</a>; <a href="/tags/shap">SHAP</a>; <a href="/tags/shapforxgboost">SHAPforxgboost</a>
  </p>
  
  

</div>



<main>

<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>
<link href="/rmarkdown-libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
<script src="/rmarkdown-libs/pagedtable/js/pagedtable.js"></script>

<div id="TOC">
<ul>
<li><a href="#the-shapforxgboost-package">The <code>SHAPforxgboost</code> package</a></li>
<li><a href="#why-shap-values">Why SHAP values</a><ul>
<li><a href="#local-explanation">Local explanation</a></li>
<li><a href="#consistency-in-global-feature-importance">Consistency in global feature importance</a></li>
</ul></li>
<li><a href="#shap-plots">SHAP plots</a><ul>
<li><a href="#summary-plot">Summary plot</a></li>
<li><a href="#dependence-plot">Dependence plot</a></li>
<li><a href="#interaction-effects">Interaction effects</a></li>
<li><a href="#shap-force-plot">SHAP force plot</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="the-shapforxgboost-package" class="section level1">
<h1>The <code>SHAPforxgboost</code> package</h1>
<p>I wrote the R package <a href="https://cran.r-project.org/web/packages/SHAPforxgboost/index.html"><strong>SHAPforxgboost</strong></a> to cover all the plotting functions illustrated in this post. This post serves as the vignette for the package.</p>
<p>Please install from CRAN or <a href="https://github.com/liuyanguu/SHAPforxgboost">Github</a>.</p>
<pre class="r"><code>install.packages(&quot;SHAPforxgboost&quot;)
# or 
devtools::install_github(&quot;liuyanguu/SHAPforxgboost&quot;)</code></pre>
</div>
<div id="why-shap-values" class="section level1">
<h1>Why SHAP values</h1>
<p>SHAP’s main advantages are <strong>local explanation</strong> and <strong>consistency</strong> in global model structure.</p>
<p>Tree-based machine learning models (random forest, gradient boosted trees, XGBoost) are the most popular non-linear models today. SHAP (SHapley Additive exPlanations) values is claimed to be the most advanced method to interpret results from tree-based models. It is based on Shaply values from game theory, and presents the feature importance using by marginal contribution to the model outcome.</p>
<p>This <a href="https://github.com/slundberg/shap">Github page</a> explains the Python package developed by Scott Lundberg. Here we show all the visualizations in R. The <code>xgboost::xgb.shap.plot</code> function can also make simple dependence plot.</p>
<div id="local-explanation" class="section level2">
<h2>Local explanation</h2>
<pre class="r"><code># run the model with built-in data
suppressPackageStartupMessages({
library(&quot;SHAPforxgboost&quot;); library(&quot;ggplot2&quot;); library(&quot;xgboost&quot;)
library(&quot;data.table&quot;); library(&quot;here&quot;)
})

y_var &lt;-  &quot;diffcwv&quot;
dataX &lt;- as.matrix(dataXY_df[,-..y_var])
# hyperparameter tuning results
param_list &lt;- list(objective = &quot;reg:squarederror&quot;,  # For regression
                   eta = 0.02,
                   max_depth = 10,
                   gamma = 0.01,
                   subsample = 0.95
                   )
mod &lt;- xgboost::xgboost(data = dataX, 
                        label = as.matrix(dataXY_df[[y_var]]), 
                        params = param_list, nrounds = 10,
                        verbose = FALSE, nthread = parallel::detectCores() - 2,
                        early_stopping_rounds = 8)
                       
# To return the SHAP values and ranked features by mean|SHAP|
shap_values &lt;- shap.values(xgb_model = mod, X_train = dataX)
# The ranked features by mean |SHAP|
shap_values$mean_shap_score</code></pre>
<pre><code>##          dayint       Column_WV AOT_Uncertainty   dist_water_km             aod 
##    0.0164610224    0.0117145059    0.0072662862    0.0055210823    0.0040159752 
##            elev     DevAll_P1km           RelAZ  forestProp_1km 
##    0.0038652825    0.0023151470    0.0008675773    0.0003986912</code></pre>
<p>SHAP values are calculated for each cell in the training dataset. The SHAP values dataset (<code>shap_values$shap_score</code>) has the same dimension (10148,9) as the dataset of the independent variables (10148,9) fit into the xgboost model.</p>
<p>The sum of each row’s SHAP values (plus the <strong>BIAS</strong> column, which is like an intercept) is the predicted model output. As in the following table of SHAP values, <code>rowSum</code> equals the output <code>predict(xgb_mod)</code>. I.e., the explanation’s attribution values sum up to the model output (last column in the table below). This is the case in this example, but not so if you are running e.g. 5-fold cross-validation.</p>
<pre class="r"><code># to show that `rowSum` is the output:
shap_data &lt;- copy(shap_values$shap_score)
shap_data[, BIAS := shap_values$BIAS0]
pred_mod &lt;- predict(mod, dataX, ntreelimit = 10)
shap_data[, `:=`(rowSum = round(rowSums(shap_data),6), pred_mod = round(pred_mod,6))]
rmarkdown::paged_table(shap_data[1:20,])</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["dayint"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Column_WV"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["AOT_Uncertainty"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["elev"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["aod"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["RelAZ"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["DevAll_P1km"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["dist_water_km"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["forestProp_1km"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["BIAS"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["rowSum"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["pred_mod"],"name":[12],"type":["dbl"],"align":["right"]}],"data":[{"1":"-0.02512725","2":"-2.579237e-04","3":"-0.0084221549","4":"0.0079296343","5":"-0.0107030161","6":"-3.599464e-04","7":"-8.779828e-04","8":"0.0033823210","9":"5.747727e-05","10":"0.417567","11":"0.383188","12":"0.383188"},{"1":"-0.02517161","2":"-4.707105e-04","3":"-0.0105197504","4":"-0.0047914865","5":"-0.0253382195","6":"-1.252566e-03","7":"-3.342269e-03","8":"-0.0156090092","9":"-1.802564e-04","10":"0.417567","11":"0.330891","12":"0.330891"},{"1":"-0.03124691","2":"-8.366045e-04","3":"-0.0003103802","4":"-0.0018683925","5":"-0.0104470197","6":"-6.829582e-04","7":"2.568023e-03","8":"0.0020485527","9":"-1.547185e-05","10":"0.417567","11":"0.376776","12":"0.376776"},{"1":"-0.03530009","2":"-3.965796e-03","3":"-0.0202379748","4":"-0.0030842710","5":"-0.0206626523","6":"-1.439516e-03","7":"1.171224e-03","8":"-0.0141980052","9":"1.572551e-04","10":"0.417567","11":"0.320007","12":"0.320007"},{"1":"-0.01629014","2":"-8.606741e-03","3":"0.0034891085","4":"0.0035692565","5":"0.0008110153","6":"-3.033155e-04","7":"-2.463328e-04","8":"0.0013446093","9":"6.398254e-05","10":"0.417567","11":"0.401398","12":"0.401398"},{"1":"-0.01745438","2":"-6.209470e-04","3":"0.0011335793","4":"-0.0009226634","5":"0.0020744787","6":"-1.555696e-04","7":"1.075144e-03","8":"-0.0023404141","9":"1.483818e-04","10":"0.417567","11":"0.400505","12":"0.400505"},{"1":"-0.01891590","2":"-5.327203e-03","3":"0.0010200819","4":"-0.0029446082","5":"0.0015204573","6":"-2.229926e-04","7":"8.649328e-04","8":"-0.0012631265","9":"2.177754e-05","10":"0.417567","11":"0.392320","12":"0.392320"},{"1":"-0.01463646","2":"-3.635206e-03","3":"-0.0070708729","4":"0.0029852372","5":"0.0039614504","6":"-2.905147e-04","7":"-9.170818e-05","8":"0.0014928372","9":"5.134134e-05","10":"0.417567","11":"0.400333","12":"0.400333"},{"1":"-0.01450177","2":"4.406898e-03","3":"-0.0058671264","4":"-0.0010832315","5":"0.0034831432","6":"-2.481457e-04","7":"-2.551501e-04","8":"-0.0039535495","9":"-7.440009e-05","10":"0.417567","11":"0.399474","12":"0.399474"},{"1":"-0.01554643","2":"5.986372e-05","3":"-0.0061168470","4":"0.0002918497","5":"0.0046576816","6":"-1.007339e-04","7":"1.063115e-03","8":"-0.0024847796","9":"8.293920e-05","10":"0.417567","11":"0.399474","12":"0.399474"},{"1":"-0.01521494","2":"5.117007e-04","3":"-0.0064541730","4":"0.0006574338","5":"0.0019668702","6":"-1.128574e-04","7":"9.237871e-04","8":"-0.0030058858","9":"1.086933e-04","10":"0.417567","11":"0.396948","12":"0.396948"},{"1":"-0.01533218","2":"-3.760019e-03","3":"-0.0054974332","4":"-0.0003850806","5":"0.0031928632","6":"-2.324403e-04","7":"8.023523e-04","8":"-0.0008121239","9":"6.070643e-06","10":"0.417567","11":"0.395549","12":"0.395549"},{"1":"-0.01677677","2":"-8.184441e-03","3":"0.0023931658","4":"0.0037290785","5":"0.0018768881","6":"-2.862476e-04","7":"-1.955940e-04","8":"0.0012279755","9":"4.738041e-05","10":"0.417567","11":"0.401398","12":"0.401398"},{"1":"-0.01740731","2":"-1.812330e-03","3":"0.0018528623","4":"-0.0005146732","5":"0.0019964534","6":"-2.892063e-04","7":"1.075238e-03","8":"-0.0021151600","9":"1.517325e-04","10":"0.417567","11":"0.400505","12":"0.400505"},{"1":"-0.01938305","2":"-7.173172e-03","3":"0.0036213936","4":"-0.0037015721","5":"0.0023304978","6":"-3.363185e-04","7":"6.261669e-04","8":"-0.0012670934","9":"3.656122e-05","10":"0.417567","11":"0.392320","12":"0.392320"},{"1":"-0.02164203","2":"1.012274e-02","3":"-0.0045267660","4":"-0.0049299477","5":"-0.0134046432","6":"-9.427884e-04","7":"-1.100965e-03","8":"-0.0036362973","9":"-1.419028e-04","10":"0.417567","11":"0.377364","12":"0.377364"},{"1":"-0.01664408","2":"-1.544298e-03","3":"-0.0044902237","4":"-0.0003809257","5":"0.0051075164","6":"-3.766953e-05","7":"9.993763e-04","8":"-0.0025114114","9":"8.385420e-05","10":"0.417567","11":"0.398149","12":"0.398149"},{"1":"-0.01708369","2":"-5.740270e-03","3":"-0.0021639667","4":"-0.0014803428","5":"0.0042529162","6":"-1.803587e-04","7":"8.346377e-04","8":"-0.0004769820","9":"2.006100e-05","10":"0.417567","11":"0.395549","12":"0.395549"},{"1":"-0.01517174","2":"-6.204172e-03","3":"-0.0046353028","4":"0.0026486048","5":"0.0025614225","6":"-2.583394e-04","7":"-3.578495e-04","8":"0.0012917498","9":"6.297311e-05","10":"0.417567","11":"0.397504","12":"0.397504"},{"1":"-0.01693953","2":"-2.882928e-03","3":"0.0042684609","4":"-0.0038960399","5":"0.0047521330","6":"-2.893288e-04","7":"-2.039634e-04","8":"-0.0016760333","9":"-1.951585e-04","10":"0.417567","11":"0.400505","12":"0.400505"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>This offers model explanation for each observation in the dataset. And offers lots of flexibility when summarizing the whole model.</p>
</div>
<div id="consistency-in-global-feature-importance" class="section level2">
<h2>Consistency in global feature importance</h2>
<p><strong>And why feature importance by Gain is inconsistent</strong></p>
<p>Consistency means it is legitimate to compare feature importance across different models. When we modify the model to make a feature more important, the feature importance should increase. The paper used the following example:</p>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/SHAPsuppfig2.JPG" />
<em>paper 2, <a href="https://arxiv.org/abs/1905.04610">S. Lundberg 2019 arXiv:1905.04610</a></em></p>
<p>Use the dataset of Model A above as a simple example, which feature goes <strong>first</strong> into the dataset generates <strong>opposite</strong> feature importance by Gain: whichever goes later (lower in the tree) gets more credit. Notice below the feature importance from <code>xgb.importance</code> were flipped.</p>
<pre class="r"><code>library(xgboost)
d &lt;- data.table::as.data.table(cbind(Fever = c(0,0,1,1), Cough = c(0,1,0,1), y = c(0,0,0,80)))
knitr::kable(d)</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">Fever</th>
<th align="right">Cough</th>
<th align="right">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">80</td>
</tr>
</tbody>
</table>
<pre class="r"><code>X1 = as.matrix(d[,.(Fever, Cough)])
X2 = as.matrix(d[,.(Cough, Fever)])
m1 = xgboost(
  data = X1, label = d$y,base_score = 0, gamma = 0, eta = 1, lambda = 0,nrounds = 1, verbose = F)
m2 = xgboost(
  data = X2, label = d$y,base_score = 0, gamma = 0, eta = 1, lambda = 0,nrounds = 1, verbose = F)
xgb.importance(model = m1)</code></pre>
<pre><code>##    Feature      Gain     Cover Frequency
## 1:   Cough 0.6666667 0.3333333       0.5
## 2:   Fever 0.3333333 0.6666667       0.5</code></pre>
<pre class="r"><code>xgb.importance(model = m2)</code></pre>
<pre><code>##    Feature      Gain     Cover Frequency
## 1:   Fever 0.6666667 0.3333333       0.5
## 2:   Cough 0.3333333 0.6666667       0.5</code></pre>
So in short, the order/structure of how the tree is built doesn’t matter for SHAP, but matters for Gain, and the mean absolute SHAP is the same (20 vs. 20). The SHAP scores (SHAP.Fever, SHAP.Cough) for model <code>m1</code> and <code>m2</code>:
Model <code>m1</code>:
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["x.Fever"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["x.Cough"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["y.actual"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["y.pred"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["SHAP.Fever"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["SHAP.Cough"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["BIAS.BIAS"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"0","2":"0","3":"0","4":"0","5":"-10","6":"-10","7":"20"},{"1":"0","2":"1","3":"0","4":"0","5":"-30","6":"10","7":"20"},{"1":"1","2":"0","3":"0","4":"0","5":"10","6":"-30","7":"20"},{"1":"1","2":"1","3":"80","4":"80","5":"30","6":"30","7":"20"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
Model <code>m2</code>:
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["x.Cough"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["x.Fever"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["y.actual"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["y.pred"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["SHAP.Cough"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["SHAP.Fever"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["BIAS.BIAS"],"name":[7],"type":["dbl"],"align":["right"]}],"data":[{"1":"0","2":"0","3":"0","4":"0","5":"-10","6":"-10","7":"20"},{"1":"1","2":"0","3":"0","4":"0","5":"10","6":"-30","7":"20"},{"1":"0","2":"1","3":"0","4":"0","5":"-30","6":"10","7":"20"},{"1":"1","2":"1","3":"80","4":"80","5":"30","6":"30","7":"20"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Moreover, comparing Model B to Model A in the figure above, Model B’s output was actually revised in a way that it relies more on a given feature (Cough, output scores increased by 10), so cough should be a more important feature. While Gain still get it wrong, SHAP reflects the correct feature importance.</p>
</div>
</div>
<div id="shap-plots" class="section level1">
<h1>SHAP plots</h1>
<div id="summary-plot" class="section level2">
<h2>Summary plot</h2>
<p>The summary plot shows global feature importance. The sina plots show the distribution of feature contributions to the model output (in this example, the predictions of CWV measurement error) using SHAP values of each feature for every observation. Each dot is an observation (station-day).</p>
<pre class="r"><code># To prepare the long-format data:
shap_long &lt;- shap.prep(xgb_model = mod, X_train = dataX)
# is the same as: using given shap_contrib
shap_long &lt;- shap.prep(shap_contrib = shap_values$shap_score, X_train = dataX)</code></pre>
<pre class="r"><code># **SHAP summary plot**
shap.plot.summary(shap_long)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-8-1.png" width="576" /></p>
<p><strong>Alternative ways to make the same plot:</strong></p>
<pre class="r"><code># option 1: from the xgboost model
shap.plot.summary.wrap1(model = mod, X = dataX)


# option 2: supply a self-made SHAP values dataset (e.g. sometimes as output from cross-validation)
shap.plot.summary.wrap2(shap_score = shap_values$shap_score, X = dataX)</code></pre>
</div>
<div id="dependence-plot" class="section level2">
<h2>Dependence plot</h2>
<p>It plots the SHAP values against the feature values for each variable. Again, each dot is a station-day observation.</p>
<pre class="r"><code>g1 &lt;- shap.plot.dependence(data_long = shap_long, x = &#39;dayint&#39;, y = &#39;dayint&#39;, color_feature = &#39;Column_WV&#39;) + ggtitle(&quot;(A) SHAP values of Time trend vs. Time trend&quot;)
g2 &lt;- shap.plot.dependence(data_long = shap_long, x = &#39;dayint&#39;, y = &#39;Column_WV&#39;, color_feature = &#39;Column_WV&#39;) +  ggtitle(&quot;(B) SHAP values of CWV vs. Time trend&quot;)

gridExtra::grid.arrange(g1, g2, ncol = 2)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-10-1.png" width="960" /></p>
<ol style="list-style-type: upper-alpha">
<li>SHAP values showing the contribution of the time trend to predictions. The color represents the MAIAC CWV for each observation (purple high, yellow low). The LOESS (locally estimated scatterplot smoothing) curve is overlaid in red.<br />
</li>
<li>SHAP values showing the contribution of the MAIAC CWV to predictions of CWV measurement error shown across the time period of the study. Note distinct y-axis scales for Terra and Aqua datasets. The color represents the MAIAC CWV for each observation (purple high, yellow low).</li>
</ol>
<p>Here I choose to plot top 4 features using function <code>shap.plot.dependence</code>.<br />
Plot SHAP value against feature value, without <code>color_feature</code> but has marginal distribution:</p>
<pre class="r"><code>fig_list &lt;- lapply(names(shap_values$mean_shap_score)[1:4], 
                   shap.plot.dependence, data_long = shap_long)
gridExtra::grid.arrange(grobs = fig_list, ncol = 2)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-11-1.png" width="960" /></p>
</div>
<div id="interaction-effects" class="section level2">
<h2>Interaction effects</h2>
<p>SHAP interaction values separate the impact of variable into main effects and interaction effects. They add up roughly to the dependence plot.</p>
<p>Quote paper 2: “SHAP <strong>interaction values</strong> can be interpreted as the difference between the SHAP values for feature i when feature j is <strong>present</strong> and
the SHAP values for feature i when feature j is <strong>absent</strong>.”</p>
<p>The SHAP interaction values take time since it calculates all the combinations.</p>
<pre class="r"><code># prepare the data using either: 
# (this step is slow since it calculates all the combinations of features.)
shap_int &lt;- shap.prep.interaction(xgb_mod = mod, X_train = dataX)
# or:
shap_int &lt;- predict(mod, dataX, predinteraction = TRUE) # (the same)</code></pre>
<pre class="r"><code># **SHAP interaction effect plot **
# if `data_int` is supplied, the same function will plot the interaction effect:
g3 &lt;- shap.plot.dependence(data_long = shap_long,
                           data_int = shap_int,
                           x= &quot;dayint&quot;, y = &quot;Column_WV&quot;, 
                           color_feature = &quot;Column_WV&quot;)
g4 &lt;- shap.plot.dependence(data_long = shap_long,
                           data_int = shap_int,
                           x= &quot;Column_WV&quot;, y = &quot;AOT_Uncertainty&quot;, 
                           color_feature = &quot;AOT_Uncertainty&quot;)
gridExtra::grid.arrange(g3, g4, ncol=2)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-14-1.png" width="960" /></p>
<p>Here I show the interaction effects between Time trend and CWV (LEFT), and between Blue band uncertainty and CWV (RIGHT).</p>
</div>
<div id="shap-force-plot" class="section level2">
<h2>SHAP force plot</h2>
<p>The SHAP force plot basically stacks these SHAP values for each observation, and show how the final output was obtained as a sum of each predictor’s attribution.</p>
<pre class="r"><code># choose to show top 4 features by setting `top_n = 4`, 
# set 6 clustering groups of observations.  
plot_data &lt;- shap.prep.stack.data(shap_contrib = shap_values$shap_score, top_n = 4, n_groups = 6)
# you may choose to zoom in at a location, and set y-axis limit using `y_parent_limit`  
shap.plot.force_plot(plot_data, zoom_in_location = 5000, y_parent_limit = c(-0.1,0.1))</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-15-1.png" width="768" /></p>
<pre class="r"><code># plot the 6 clusters
shap.plot.force_plot_bygroup(plot_data)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-15-2.png" width="768" /></p>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p>Recent submitted paper from my lab that applies these figures:
<a href="http://doi.org/10.5281/zenodo.3334713">Gradient Boosting Machine Learning to Improve Satellite-Derived Column Water Vapor Measurement Error</a></p>
<p>Paper 1. 2017 <a href="https://arxiv.org/abs/1705.07874">A Unified Approach to Interpreting Model Predictions</a><br />
Paper 2. 2019 <a href="https://arxiv.org/abs/1802.03888">Consistent Individualized Feature Attribution for Tree
Ensembles</a><br />
Paper 3. 2019 <a href="https://arxiv.org/abs/1905.04610">Explainable AI for Trees: From Local Explanations to Global Understanding</a></p>
</div>

</main>















<section class="article-meta article-footer">
  <h3>About the Author</h3>
  
    <p>Yang Liu (刘杨) is a Statistician working in New York City.</p>
  
</section>






<nav class="post-nav">
  <span class="nav-prev"><a href="/post/2019/07/28/some-experience-on-writing-r-package/">&larr; Notes on writing an R package</a></span>
  <span class="nav-next"><a href="/post/2019/02/24/shiny-in-blogdown/">Shiny in Blogdown &rarr;</a></span>
</nav>


<div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://liuyanguu.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</article>
</div>

<script async src="//yihui.org/js/center-img.js"></script>

<footer>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-122668586-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "liuyanguu" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



<div class="footer">
  <ul class="menu">
    
    <li><a href="/"><span data-hover="Home">Home</span></a></li>
    
    <li><a href="/tags/"><span data-hover="Tags">Tags</span></a></li>
    
    <li><a href="/categories/"><span data-hover="Categories">Categories</span></a></li>
    
    <li><a href="/about-me/"><span data-hover="About Me">About Me</span></a></li>
    
  </ul>
  
  <div class="copyright">@2020 Yang Liu <em>liuyanguu</em>. Powered by Github. Blogdown and Hugo Theme made by Yihui Xie.</div>
  
</div>
</footer>


<script src="//yihui.org/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>



<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>
<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-122668586-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


</body>
</html>

