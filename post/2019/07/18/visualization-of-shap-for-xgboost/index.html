<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>SHAP visualization for XGBoost in R | Welcome to my blog</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <link href="//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">

  </head>

  <body class="page">
    <nav class="header">
      <div class="banner">
<a href="/">

<img src="/ocean%202.jpg" alt="Text on Image" />
</a>
</div>

      <div class="head-meta">
      
        <span><a href="/">&larr; Back to Home</a></span>
        <span class="date">2019-07-18</span>
        
        
        
          
        
        
        
        <span><a href="https://github.com/liuyanguu/Blogdown/edit/master/hugo-xmag/content/post/2019-07-18-visualization-of-shap-for-xgboost.Rmd">Edit this page &rarr;</a></span>
        
        
      
      </div>
    </nav>

<div class="container">
<article>
<div class="article-meta">

  <div class="categories">
  
    <a href="/categories/machine-learning">Machine Learning</a>
  
     &hercon; <a href="/categories/data-visualization">Data Visualization</a>
  
  </div>

  <h1><span class="title">SHAP visualization for XGBoost in R</span></h1>

  
  <h3 class="author">Yang Liu
</h3>
  

  
  <p>Tags: <a href="/tags/xgboost">XGBoost</a>; <a href="/tags/shap">SHAP</a>; <a href="/tags/shapforxgboost">shapforxgboost</a>
  </p>
  
  

</div>



<main>
<link href="/rmarkdown-libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
<script src="/rmarkdown-libs/pagedtable/js/pagedtable.js"></script>

<div id="TOC">
<ul>
<li><a href="#shap-package-in-r">SHAP package in <strong>R</strong></a></li>
<li><a href="#why-shap-values">Why SHAP values</a><ul>
<li><a href="#local-explanation">Local Explanation</a></li>
<li><a href="#consistency-in-global-feature-importance">Consistency in Global Feature Importance</a></li>
</ul></li>
<li><a href="#shap-plots">SHAP plots</a><ul>
<li><a href="#shap-force-plot">SHAP force plot</a></li>
<li><a href="#summary-plot">Summary plot</a></li>
<li><a href="#dependence-plot">Dependence plot</a></li>
<li><a href="#interaction-values">Interaction values</a></li>
</ul></li>
</ul>
</div>

<div id="shap-package-in-r" class="section level1">
<h1>SHAP package in <strong>R</strong></h1>
<p>The R plotting functions used in this blog were combined into R package **SHAPforxgboost".
To install, please download from the <a href="https://github.com/liuyanguu/SHAPforxgboost">github</a>.
Still under further revise.</p>
<pre class="r"><code>devtools::install_github(&quot;liuyanguu/SHAPforxgboost&quot;)</code></pre>
</div>
<div id="why-shap-values" class="section level1">
<h1>Why SHAP values</h1>
<p>SHAP’s main advantages are <strong>local explanation</strong> and <strong>consistency</strong> in global model structure.</p>
<p>Tree-based machine learning models (random forest, gradient boosted trees, XGBoost) are the most popular non-linear models today. SHAP (SHapley Additive exPlnation) values is claimed to be the most advanced method to interpret results from tree-based models. It was based on Shaply values from game theory.</p>
<p>The <a href="https://github.com/slundberg/shap">github page</a> that explains the Python package developed by <em>Scott Lundberg</em>. Here we show all the visualizations in R. In r package <em>xgboost</em> there is only one function <em>xgb.plot.shap</em> that can make some simple dependence plots.</p>
<p>Main references by Slundberg:<br />
Paper 1. 2017 <a href="https://arxiv.org/abs/1705.07874">A Unified Approach to Interpreting Model Predictions</a><br />
Paper 2. 2019 <a href="https://arxiv.org/abs/1802.03888">Consistent Individualized Feature Attribution for Tree
Ensembles</a><br />
Paper 3. 2019 <a href="https://arxiv.org/abs/1905.04610">Explainable AI for Trees: From Local Explanations to Global Understanding</a></p>
<div id="local-explanation" class="section level2">
<h2>Local Explanation</h2>
<p>Shapley values are caculated across the entire dataset. The SHAP values dataset has the same dimention (10148,9) as the dataset of the independent variables (10148,9) fit into the xgboost model.</p>
<p>The sum of each row’s SHAP values (plus the bias, which is like an intercept) is the predicted model output. As in the following table of SHAP values, <code>rowSum</code> equals the output <code>predict(xgb_mod)</code>. I.e., the explanation’s attribution values sum up to the model output.</p>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["dayint"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Column_WV"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["AOT_Uncertainty"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["elev"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["aod"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["RelAZ"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["DevAll_P1km"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["dist_water_km"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["forestProp_1km"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["BIAS"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["rowSum"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["pred_mod"],"name":[12],"type":["dbl"],"align":["right"]}],"data":[{"1":"-0.18715677","2":"-0.031067915","3":"-0.042542458","4":"0.031067742","5":"-0.0815232396","6":"-0.0094383266","7":"0.003468891","8":"0.0166249666","9":"0.004934906","10":"0.04338279","11":"-0.252249","12":"-0.252248"},{"1":"-0.12964958","2":"-0.009885377","3":"-0.043589681","4":"-0.031356119","5":"-0.1450539678","6":"0.0046048006","7":"-0.023994194","8":"-0.0750681460","9":"-0.016985688","10":"0.04338279","11":"-0.427595","12":"-0.427592"},{"1":"-0.25374624","2":"-0.045215413","3":"-0.013490994","4":"-0.038848273","5":"-0.0869967267","6":"-0.0096156942","7":"0.004589455","8":"-0.0288857892","9":"0.003624398","10":"0.04338279","11":"-0.425202","12":"-0.425200"},{"1":"-0.18323998","2":"-0.043409277","3":"-0.106642842","4":"-0.028045641","5":"-0.1206713319","6":"-0.0127560785","7":"-0.021616094","8":"-0.0411532968","9":"0.008067717","10":"0.04338279","11":"-0.506084","12":"-0.506081"},{"1":"-0.11401504","2":"-0.025009969","3":"0.022383327","4":"0.022031108","5":"-0.0006215787","6":"-0.0021892134","7":"0.005889706","8":"0.0054647080","9":"0.004676695","10":"0.04338279","11":"-0.038007","12":"-0.038008"},{"1":"-0.10267494","2":"-0.002558434","3":"0.008135342","4":"-0.013826885","5":"0.0016683409","6":"-0.0054014330","7":"-0.009841926","8":"-0.0029660626","9":"0.006683792","10":"0.04338279","11":"-0.077399","12":"-0.077400"},{"1":"-0.13547783","2":"-0.012119506","3":"0.008484396","4":"-0.024734786","5":"-0.0014629379","6":"-0.0039268318","7":"0.003149311","8":"-0.0170685146","9":"0.002660275","10":"0.04338279","11":"-0.137114","12":"-0.137113"},{"1":"-0.09839460","2":"0.006818605","3":"-0.043481231","4":"0.017092850","5":"0.0229927097","6":"-0.0007108831","7":"0.005390577","8":"0.0088423491","9":"0.003532766","10":"0.04338279","11":"-0.034534","12":"-0.034534"},{"1":"-0.09118569","2":"0.059970852","3":"-0.066366374","4":"-0.013478030","5":"0.0061395997","6":"0.0002563516","7":"-0.003441083","8":"-0.0259610321","9":"-0.008752892","10":"0.04338279","11":"-0.099436","12":"-0.099436"},{"1":"-0.09399413","2":"0.007784905","3":"-0.072339907","4":"-0.011641352","5":"0.0242972262","6":"-0.0059533017","7":"-0.010730079","8":"-0.0086742062","9":"0.004299855","10":"0.04338279","11":"-0.123568","12":"-0.123568"},{"1":"-0.09959194","2":"0.012008791","3":"-0.061421499","4":"-0.009878984","5":"-0.0168019254","6":"-0.0004406802","7":"-0.011182155","8":"-0.0140221165","9":"0.004142347","10":"0.04338279","11":"-0.153805","12":"-0.153805"},{"1":"-0.11740648","2":"0.003290213","3":"-0.045823935","4":"-0.020620992","5":"0.0039394405","6":"-0.0021595182","7":"0.003970480","8":"-0.0121408273","9":"0.001049619","10":"0.04338279","11":"-0.142519","12":"-0.142520"},{"1":"-0.11837890","2":"-0.027577521","3":"0.008354975","4":"0.019331476","5":"0.0112489099","6":"-0.0020722104","7":"0.005616670","8":"0.0057744100","9":"0.004772345","10":"0.04338279","11":"-0.049547","12":"-0.049547"},{"1":"-0.10602196","2":"-0.017489864","3":"0.015197348","4":"-0.012273921","5":"0.0025097895","6":"-0.0021004984","7":"-0.006961844","8":"-0.0008688157","9":"0.008245739","10":"0.04338279","11":"-0.076381","12":"-0.076381"},{"1":"-0.14001110","2":"-0.020041713","3":"0.035514940","4":"-0.024146084","5":"0.0280121844","6":"-0.0009258876","7":"0.001782326","8":"-0.0189278349","9":"0.003199620","10":"0.04338279","11":"-0.092161","12":"-0.092160"},{"1":"-0.07728018","2":"0.074728101","3":"-0.024501290","4":"-0.009976464","5":"-0.0358427614","6":"0.0065780962","7":"-0.007042302","8":"-0.0205744430","9":"-0.004872040","10":"0.04338279","11":"-0.055400","12":"-0.055402"},{"1":"-0.10048369","2":"-0.007221894","3":"-0.032718115","4":"-0.015667135","5":"0.0355319791","6":"-0.0054386123","7":"-0.011140550","8":"-0.0097863171","9":"0.005385204","10":"0.04338279","11":"-0.098156","12":"-0.098156"},{"1":"-0.12534212","2":"-0.010824366","3":"-0.016725406","4":"-0.022520537","5":"0.0332389995","6":"-0.0049382970","7":"0.004164279","8":"-0.0171724353","9":"0.002152309","10":"0.04338279","11":"-0.114585","12":"-0.114584"},{"1":"-0.10409787","2":"-0.016006416","3":"-0.024844673","4":"0.020165309","5":"0.0066079525","6":"-0.0028690661","7":"0.005537408","8":"0.0090354336","9":"0.004151466","10":"0.04338279","11":"-0.058938","12":"-0.058937"},{"1":"-0.11528442","2":"0.004500886","3":"0.042238023","4":"-0.014222793","5":"0.0273922328","6":"-0.0037647171","7":"-0.001990702","8":"-0.0152933709","9":"-0.008244956","10":"0.04338279","11":"-0.041287","12":"-0.041287"},{"1":"-0.11656743","2":"-0.023387292","3":"-0.009356011","4":"-0.009143895","5":"-0.0208226219","6":"-0.0037388646","7":"-0.006980686","8":"-0.0042926460","9":"0.009554730","10":"0.04338279","11":"-0.141352","12":"-0.141351"},{"1":"-0.14012492","2":"-0.014302307","3":"0.015931830","4":"-0.022592893","5":"0.0175349601","6":"-0.0044122408","7":"0.003044810","8":"-0.0180001333","9":"0.003710948","10":"0.04338279","11":"-0.115827","12":"-0.115827"},{"1":"-0.11826131","2":"-0.033812970","3":"0.016363693","4":"0.019668225","5":"-0.0001721819","6":"-0.0035931296","7":"0.004827132","8":"0.0045802798","9":"0.004429853","10":"0.04338279","11":"-0.062588","12":"-0.062588"},{"1":"-0.10903507","2":"-0.036489811","3":"0.006512624","4":"-0.012283617","5":"0.0195753723","6":"-0.0016612468","7":"-0.006123367","8":"0.0003110451","9":"0.008055500","10":"0.04338279","11":"-0.087756","12":"-0.087756"},{"1":"-0.14956295","2":"-0.038630322","3":"0.016869539","4":"-0.022014769","5":"0.0239063706","6":"-0.0004476100","7":"0.002090851","8":"-0.0202623159","9":"0.002958729","10":"0.04338279","11":"-0.141710","12":"-0.141709"},{"1":"-0.12475270","2":"-0.043940909","3":"-0.075587615","4":"0.022011196","5":"0.0029847433","6":"-0.0101475958","7":"0.006893964","8":"0.0139649948","9":"0.004842665","10":"0.04338279","11":"-0.160348","12":"-0.160348"},{"1":"-0.13565357","2":"-0.023931466","3":"-0.058972284","4":"-0.024380034","5":"0.0160689484","6":"-0.0070775207","7":"-0.010869136","8":"-0.0366374552","9":"-0.011445017","10":"0.04338279","11":"-0.249515","12":"-0.249515"},{"1":"-0.25385344","2":"-0.030712744","3":"0.027058763","4":"0.022032510","5":"0.0073433197","6":"-0.0361521132","7":"0.004387179","8":"0.0084044132","9":"0.005609675","10":"0.04338279","11":"-0.202500","12":"-0.202498"},{"1":"-0.14995360","2":"-0.021509238","3":"0.053598445","4":"-0.010622251","5":"-0.0144325672","6":"0.0007373059","7":"-0.003630016","8":"0.0008640449","9":"0.009957199","10":"0.04338279","11":"-0.091608","12":"-0.091606"},{"1":"-0.13132517","2":"-0.037450198","3":"0.042510960","4":"-0.008883680","5":"0.0087455176","6":"-0.0021514141","7":"-0.001365387","8":"0.0102984514","9":"0.013207970","10":"0.04338279","11":"-0.063030","12":"-0.063028"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>This offers model explanation for each observation in the dataset. And offers lots of flexibility when summarizing the whole model.</p>
</div>
<div id="consistency-in-global-feature-importance" class="section level2">
<h2>Consistency in Global Feature Importance</h2>
<p><strong>And why feature importance by Gain is inconsistent</strong></p>
<p>Consistency means it is legitimate to compare feature importance across different models. When we modify the model to make a feature more important, the feature importance should increase. The paper used the following example:</p>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/SHAPsuppfig2.JPG" />
<em>paper 2, <a href="https://arxiv.org/abs/1905.04610">S. Lundberg 2019 arXiv:1905.04610</a></em></p>
<p>Use the dataset of Model A as a simple example, which feature goes <strong>first</strong> into the dataset generates <strong>opposite</strong> feature importance by Gain: whichever goes later (lower in the tree) gets more credit. Notice the results from <code>xgb.importance</code> were flipped.</p>
<p>The simple example:</p>
<table>
<thead>
<tr class="header">
<th align="right">Fever</th>
<th align="right">Cough</th>
<th align="right">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">80</td>
</tr>
</tbody>
</table>
<pre class="r"><code>library(xgboost)
X1 = as.matrix(d[,.(Fever, Cough)])
X2 = as.matrix(d[,.(Cough, Fever)])
m1 = xgboost(
  data = X1, label = d$y,base_score = 0, gamma = 0, eta = 1, lambda = 0,nrounds = 1,objective = &quot;reg:linear&quot;,  verbose = F)
m2 = xgboost(
  data = X2, label = d$y,base_score = 0, gamma = 0, eta = 1, lambda = 0,nrounds = 1,objective = &quot;reg:linear&quot;,verbose = F)

xgb.importance(model = m1)</code></pre>
<pre><code>##    Feature      Gain     Cover Frequency
## 1:   Cough 0.6666667 0.3333333       0.5
## 2:   Fever 0.3333333 0.6666667       0.5</code></pre>
<pre class="r"><code>xgb.importance(model = m2)</code></pre>
<pre><code>##    Feature      Gain     Cover Frequency
## 1:   Fever 0.6666667 0.3333333       0.5
## 2:   Cough 0.3333333 0.6666667       0.5</code></pre>
<p>The key message is, the order/structure of how the tree is built doesn’t matter for SHAP, but matters for Gain, since the mean absolute SHAP is always the same (20 vs. 20). The explanation in the paper is a little bit confusing.</p>
<table>
<thead>
<tr class="header">
<th align="right">x.Fever</th>
<th align="right">x.Cough</th>
<th align="right">y.actual</th>
<th align="right">y.pred</th>
<th align="right">SHAP.Fever</th>
<th align="right">SHAP.Cough</th>
<th align="right">BIAS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">-10</td>
<td align="right">-10</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">-30</td>
<td align="right">10</td>
<td align="right">20</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">10</td>
<td align="right">-30</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">80</td>
<td align="right">80</td>
<td align="right">30</td>
<td align="right">30</td>
<td align="right">20</td>
</tr>
</tbody>
</table>
<p>Moreover, comparing Model B to Model A, Model B was revised in a way that it relies more on a given feature (Cough), so cough should be a more important feature. But of course Gain still get it wrong, and only SHAP gives the correct global feature importance.</p>
</div>
</div>
<div id="shap-plots" class="section level1">
<h1>SHAP plots</h1>
<div id="shap-force-plot" class="section level2">
<h2>SHAP force plot</h2>
<p>The SHAP force plot basically stacks these SHAP values for each observation, and show how the final output was obtained as a sum of each predictor’s attribution.</p>
<p>How the plot looks like in python package by running</p>
<pre class="python"><code>shap.force_plot(explainer.expected_value, shap_values, data_X)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/Python.stackplot.PNG" /></p>
<p>Using my function in R:</p>
<pre><code>## Data has N: 10148 | zoom in length is 150 at location 6088.8</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-8-1.png" width="768" /><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-8-2.png" width="768" /></p>
</div>
<div id="summary-plot" class="section level2">
<h2>Summary plot</h2>
<p>The summary plot shows global feature importance. The sina plots show the distribution of feature contributions to the model output (in this example, the predictions of CWV measurement error) using SHAP values of each feature for every observation. Each dot is an observation (station-day).</p>
<p>The SHAP values were generated from each fold of cross-validation. As a comparison, I also show the values from final model. Kind of similar.</p>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-9-1.png" width="960" /></p>
<p>This function offers visualization improvement compared to its Python counterpart:</p>
<pre class="python"><code>shap.summary_plot(shap_values, data_X)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/Python.summaryplot.PNG" style="width:60.0%" /></p>
</div>
<div id="dependence-plot" class="section level2">
<h2>Dependence plot</h2>
<p>It plots the SHAP values against the feature values for each variable. Again, each dot is a station-day observation.</p>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-11-1.png" width="480" /></p>
<p>We can also select another feature for coloring to show some interaction.</p>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-12-1.png" width="960" /></p>
<p>(LEFT) SHAP values showing the contribution of the time trend to predictions. The color represents the MAIAC CWV for each observation (purple high, yellow low). The LOESS (locally estimated scatterplot smoothing) curve is overlaid in red.<br />
(RIGHT) SHAP values showing the contribution of the MAIAC CWV to predictions of CWV measurement error shown across the time period of the study. Note distinct y-axis scales for Terra and Aqua datasets. The color represents the MAIAC CWV for each observation (purple high, yellow low).</p>
<p>To compare Terra vs. Aqua (As in our paper)
<img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/Figure_6a_2019_06_14_SHAP_interaction.png" />
<img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/Figure_6b_2019_06_14_SHAP_interaction.png" /></p>
</div>
<div id="interaction-values" class="section level2">
<h2>Interaction values</h2>
<p>SHAP interaction values separate the impact of variable into main effects and interaction effects. They add up roughly to the dependence plot.</p>
<p>Quote paper 2: “SHAP <strong>interaction values</strong> can be interpreted as the difference between the SHAP values for feature i when feature j is <strong>present</strong> and
the SHAP values for feature i when feature j is <strong>absent</strong>.”</p>
<ul>
<li>Under work: my version doesn’t seem correct …</li>
</ul>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/figure-html/unnamed-chunk-13-1.png" width="960" /></p>
<ul>
<li>The correct interaction plot in Python:</li>
</ul>
<pre class="python"><code>shap_interaction_values = shap.TreeExplainer(model).shap_interaction_values(data_X) 
shap.dependence_plot((&quot;dayint&quot;, &quot;Column_WV&quot;),
    shap_interaction_values, data_X, dot_size=1)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/int1.PNG" style="width:50.0%" /></p>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/int2.PNG" style="width:50.0%" /></p>
<pre class="python"><code>shap.summary_plot(shap_interaction_values, data_X)</code></pre>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/Python_summary_interaction_values.png" /></p>
<p>The example in the paper 2: It shows again that the SHAP values = SHAP values without the interaction variable age + Interactive effects by age. In this example the interactive effects are highly visible.</p>
<p><img src="/post/2019-07-18-visualization-of-shap-for-xgboost_files/interactionSHAPplot.JPG" /></p>
</div>
</div>

</main>















<section class="article-meta article-footer">
  <h3>About the Author</h3>
  
    <p>Yang Liu is a (Bio)Statistician working in New York City. Website: <a href="https://liuyanguu.github.io">https://liuyanguu.github.io</a></p>
  
</section>






<nav class="post-nav">
  <span class="nav-prev"></span>
  <span class="nav-next"><a href="/post/2019/04/17/ggplot-heatmap-us-50-states-map-and-china-province-map/">ggplot heatmap US 50-state map and China province map &rarr;</a></span>
</nav>


<div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://liuyanguu.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</article>
</div>

<script async src="//yihui.name/js/center-img.js"></script>

<footer>

<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-122668586-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "liuyanguu" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>



<div class="footer">
  <ul class="menu">
    
    <li><a href="/"><span data-hover="Home">Home</span></a></li>
    
    <li><a href="/tags/"><span data-hover="Tags">Tags</span></a></li>
    
    <li><a href="/categories/"><span data-hover="Categories">Categories</span></a></li>
    
    <li><a href="/about-me/"><span data-hover="About Me">About Me</span></a></li>
    
  </ul>
  
  <div class="copyright">@2019 Yang Liu <em>liuyanguu</em>. Powered by Github. Blogdown and Hugo Theme by Yihui Xie.</div>
  
</div>
</footer>


<script src="//yihui.name/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>



<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>
<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>



<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-122668586-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


</body>
</html>

