<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SHAP on Welcome to my blog</title>
    <link>https://liuyanguu.github.io/tags/shap/</link>
    <description>Recent content in SHAP on Welcome to my blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 14 Oct 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://liuyanguu.github.io/tags/shap/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>SHAP Visualization for XGBoost</title>
      <link>https://liuyanguu.github.io/post/2018/10/14/shap-visualization-for-xgboost/</link>
      <pubDate>Sun, 14 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://liuyanguu.github.io/post/2018/10/14/shap-visualization-for-xgboost/</guid>
      <description>BackgroundSummary plotFunction to get SHAP value matrixFunctions for summary plotSHAP plot for each featureSHAP stack plot for observationFunction for stack plotStack plot by clustering groups(Under further updating â€¦)
BackgroundI will illustrate the application of SHAP (SHapley Additive exPlnation) values to visualize the efforts of features on the outcome variable in a XGBoost model.
The function was developed by Scott Lundberg in Python and explained here.</description>
    </item>
    
  </channel>
</rss>